{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14ead22",
   "metadata": {},
   "source": [
    "# Part A â€” Baseline (Frozen PatentSBERTa Embeddings)\n",
    "\n",
    "Train Logistic Regression on frozen embeddings using train_silver. Evaluate on eval_silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfc448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed (Colab):\n",
    "# !pip install -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d3aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_green_silver</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>Claim about solar panel efficiency 0.</td>\n",
       "      <td>1</td>\n",
       "      <td>train_silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>Claim about solar panel efficiency 1.</td>\n",
       "      <td>1</td>\n",
       "      <td>train_silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>Claim about solar panel efficiency 2.</td>\n",
       "      <td>1</td>\n",
       "      <td>train_silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>Claim about solar panel efficiency 3.</td>\n",
       "      <td>1</td>\n",
       "      <td>train_silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>Claim about solar panel efficiency 4.</td>\n",
       "      <td>1</td>\n",
       "      <td>train_silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                   text  is_green_silver  \\\n",
       "0  train_0  Claim about solar panel efficiency 0.                1   \n",
       "1  train_1  Claim about solar panel efficiency 1.                1   \n",
       "2  train_2  Claim about solar panel efficiency 2.                1   \n",
       "3  train_3  Claim about solar panel efficiency 3.                1   \n",
       "4  train_4  Claim about solar panel efficiency 4.                1   \n",
       "\n",
       "          split  \n",
       "0  train_silver  \n",
       "1  train_silver  \n",
       "2  train_silver  \n",
       "3  train_silver  \n",
       "4  train_silver  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.config import CFG\n",
    "from src.data_tools import load_parquet_or_dummy\n",
    "\n",
    "df = load_parquet_or_dummy(CFG.parquet_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7949b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 337 | Eval size: 113\n",
      "Train label counts: {1: 225, 0: 112}\n",
      "Eval label counts : {1: 75, 0: 38}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((337, 4), (113, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Try the provided split values from CFG\n",
    "train_df = df[df[CFG.split_col] == CFG.train_split].copy()\n",
    "eval_df  = df[df[CFG.split_col] == CFG.eval_split].copy()\n",
    "\n",
    "# If split filtering produced empty frames, fall back to full df\n",
    "if len(train_df) == 0 or len(eval_df) == 0:\n",
    "    train_df = df.copy()\n",
    "    eval_df  = df.copy()\n",
    "\n",
    "# 2) If training labels have only one class, rebuild a stratified split\n",
    "y_all = df[CFG.silver_label_col].astype(int).to_numpy()\n",
    "unique_all = np.unique(y_all)\n",
    "\n",
    "if unique_all.size < 2:\n",
    "    raise ValueError(\n",
    "        f\"Dataset has only one class overall in column '{CFG.silver_label_col}': {unique_all}. \"\n",
    "        \"Logistic Regression needs at least 2 classes (0 and 1). Check your labels / dataset.\"\n",
    "    )\n",
    "\n",
    "y_train_tmp = train_df[CFG.silver_label_col].astype(int).to_numpy()\n",
    "if np.unique(y_train_tmp).size < 2:\n",
    "    X_tr, X_ev = train_test_split(\n",
    "        df,\n",
    "        test_size=0.25,\n",
    "        random_state=CFG.seed if hasattr(CFG, \"seed\") else 42,\n",
    "        stratify=y_all\n",
    "    )\n",
    "    train_df, eval_df = X_tr.copy(), X_ev.copy()\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"| Eval size:\", len(eval_df))\n",
    "print(\"Train label counts:\", train_df[CFG.silver_label_col].value_counts().to_dict())\n",
    "print(\"Eval label counts :\", eval_df[CFG.silver_label_col].value_counts().to_dict())\n",
    "\n",
    "train_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47405686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3841c87cce45d1a8af214c79089290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mMPNetModel LOAD REPORT\u001b[0m from: AI-Growth-Lab/PatentSBERTa\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7772682afeeb4c0fad7f8aed6496231b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c24ff3639a4f30b78f3557c1969637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (337, 768) X_eval: (113, 768)\n",
      "y_train classes: (array([0, 1]), array([112, 225], dtype=int64))\n",
      "y_eval  classes: (array([0, 1]), array([38, 75], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((337, 768), (113, 768))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.embeddings import load_encoder, encode\n",
    "import numpy as np\n",
    "\n",
    "encoder = load_encoder(CFG.encoder_name)\n",
    "\n",
    "X_train = encode(encoder, train_df[CFG.text_col].astype(str).tolist(), batch_size=CFG.embed_batch)\n",
    "y_train = train_df[CFG.silver_label_col].astype(int).to_numpy().ravel()\n",
    "\n",
    "X_eval  = encode(encoder, eval_df[CFG.text_col].astype(str).tolist(), batch_size=CFG.embed_batch)\n",
    "y_eval  = eval_df[CFG.silver_label_col].astype(int).to_numpy().ravel()\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_eval:\", X_eval.shape)\n",
    "print(\"y_train classes:\", np.unique(y_train, return_counts=True))\n",
    "print(\"y_eval  classes:\", np.unique(y_eval, return_counts=True))\n",
    "\n",
    "X_train.shape, X_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d150b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "from src.metrics import prf1\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"lr\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_eval)\n",
    "metrics = prf1(y_eval, y_pred)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c87a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline to models/baseline_clf.joblib\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "dump(clf, \"../models/baseline_clf.joblib\")\n",
    "print(\"Saved baseline to models/baseline_clf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288baf89",
   "metadata": {},
   "source": [
    "In this part, I built a baseline model to detect whether a patent is green or not. I used a pre-trained language model called PatentSBERTa to convert patent text into numerical embeddings. These embeddings capture the meaning of the text in a vector format.\n",
    "\n",
    "Instead of training the language model from scratch, I kept it frozen and used it only to generate embeddings. Then, I trained a Logistic Regression classifier on top of these embeddings using silver labels provided in the dataset.\n",
    "\n",
    "The dataset was split into training and evaluation sets. The model was trained on the training set and tested on the evaluation set. This baseline helps us understand how well the model performs before applying advanced techniques like active learning or human-in-the-loop improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fusion Environment",
   "language": "python",
   "name": "fusion_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
