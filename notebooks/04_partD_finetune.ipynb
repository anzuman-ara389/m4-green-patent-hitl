{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887e2b92",
   "metadata": {},
   "source": [
    "# Part D — Fine-tune PatentSBERTa (READY)\n",
    "\n",
    "This notebook loads the parquet, builds train/eval splits safely, applies gold overrides (if available), fine-tunes, evaluates, and saves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82313dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Environment check (needed for HuggingFace Trainer)\n",
    "import sys, subprocess, pkgutil\n",
    "\n",
    "def _pip_install(pkgs):\n",
    "    print(\"Installing:\", pkgs)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", *pkgs])\n",
    "\n",
    "need_restart = False\n",
    "\n",
    "# accelerate\n",
    "try:\n",
    "    import accelerate\n",
    "    from packaging import version\n",
    "    if version.parse(accelerate.__version__) < version.parse(\"0.26.0\"):\n",
    "        _pip_install([\"accelerate>=0.26.0\"])\n",
    "        need_restart = True\n",
    "except Exception:\n",
    "    _pip_install([\"accelerate>=0.26.0\"])\n",
    "    need_restart = True\n",
    "\n",
    "# transformers + torch extras\n",
    "try:\n",
    "    import transformers\n",
    "except Exception:\n",
    "    _pip_install([\"transformers[torch]\"])\n",
    "    need_restart = True\n",
    "\n",
    "if need_restart:\n",
    "    print(\"\\n✅ Packages updated. Please RESTART the kernel, then run all cells again.\")\n",
    "    raise SystemExit(\"Restart kernel and rerun.\")\n",
    "else:\n",
    "    print(\"✅ Environment looks good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.config import CFG\n",
    "from src.data_tools import load_parquet_or_dummy\n",
    "\n",
    "# -------- Load data --------\n",
    "df = load_parquet_or_dummy(CFG.parquet_path)\n",
    "print(\"DF shape:\", df.shape)\n",
    "\n",
    "# -------- Pick train/eval safely --------\n",
    "split_col = getattr(CFG, \"split_col\", None)\n",
    "train_split = getattr(CFG, \"train_split\", None)\n",
    "eval_split  = getattr(CFG, \"eval_split\", None)\n",
    "\n",
    "label_col = getattr(CFG, \"silver_label_col\", None)\n",
    "text_col  = getattr(CFG, \"text_col\", None)\n",
    "\n",
    "# Basic sanity\n",
    "missing = [c for c in [label_col, text_col] if (c is None or c not in df.columns)]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns in df: {missing}. Check CFG.silver_label_col / CFG.text_col.\")\n",
    "\n",
    "# Try CFG split if available\n",
    "use_cfg_split = (split_col in df.columns) and (train_split is not None) and (eval_split is not None)\n",
    "if use_cfg_split:\n",
    "    print(\"Split counts:\\n\", df[split_col].value_counts(dropna=False))\n",
    "    train_df = df[df[split_col] == train_split].copy()\n",
    "    eval_df  = df[df[split_col] == eval_split].copy()\n",
    "else:\n",
    "    train_df = df.iloc[:0].copy()\n",
    "    eval_df  = df.iloc[:0].copy()\n",
    "\n",
    "def has_two_classes(series):\n",
    "    vals = pd.Series(series).dropna().astype(int).unique()\n",
    "    return len(vals) >= 2\n",
    "\n",
    "# If CFG split failed / empty / one-class, do stratified split\n",
    "if (len(train_df) == 0) or (len(eval_df) == 0) or (not has_two_classes(train_df[label_col])):\n",
    "    print(\"⚠️ CFG split not usable (empty or one-class). Creating stratified split from full df...\")\n",
    "    y_all = df[label_col].astype(int)\n",
    "    train_df, eval_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.25,\n",
    "        random_state=getattr(CFG, \"seed\", 42),\n",
    "        stratify=y_all\n",
    "    )\n",
    "    train_df = train_df.copy()\n",
    "    eval_df  = eval_df.copy()\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"| Eval size:\", len(eval_df))\n",
    "print(\"Train label counts:\", train_df[label_col].astype(int).value_counts().to_dict())\n",
    "print(\"Eval  label counts:\", eval_df[label_col].astype(int).value_counts().to_dict())\n",
    "\n",
    "# -------- Load gold labels if available --------\n",
    "gold_path = \"../data/hitl_green_100_labeled.csv\"\n",
    "if os.path.exists(gold_path):\n",
    "    gold = pd.read_csv(gold_path)\n",
    "    print(\"Loaded gold:\", gold.shape)\n",
    "else:\n",
    "    gold = None\n",
    "    print(f\"Gold file not found at {gold_path}. Proceeding without gold overrides.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create is_green_gold (gold overrides silver, if gold file is present)\n",
    "label_col = CFG.silver_label_col\n",
    "text_col  = CFG.text_col\n",
    "doc_id_col = getattr(CFG, \"doc_id_col\", None)\n",
    "\n",
    "train_df[\"is_green_gold\"] = train_df[label_col].astype(int)\n",
    "\n",
    "if gold is not None and doc_id_col in train_df.columns and doc_id_col in gold.columns and \"is_green_human\" in gold.columns:\n",
    "    gold_map = dict(zip(gold[doc_id_col], gold[\"is_green_human\"].astype(int)))\n",
    "    mask = train_df[doc_id_col].isin(gold_map.keys())\n",
    "    train_df.loc[mask, \"is_green_gold\"] = train_df.loc[mask, doc_id_col].map(gold_map)\n",
    "    print(\"Gold overrides applied to\", int(mask.sum()), \"rows.\")\n",
    "else:\n",
    "    if gold is not None:\n",
    "        print(\"Gold loaded, but required columns missing for overrides. Skipping overrides.\")\n",
    "\n",
    "train_hf = Dataset.from_pandas(\n",
    "    train_df[[text_col, \"is_green_gold\"]]\n",
    "    .rename(columns={text_col: \"text\", \"is_green_gold\": \"label\"})\n",
    ")\n",
    "\n",
    "eval_hf = Dataset.from_pandas(\n",
    "    eval_df[[text_col, label_col]]\n",
    "    .rename(columns={text_col: \"text\", label_col: \"label\"})\n",
    ")\n",
    "\n",
    "print(\"HF train:\", train_hf)\n",
    "print(\"HF eval :\", eval_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.encoder_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(CFG.encoder_name, num_labels=2)\n",
    "\n",
    "def tok(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=getattr(CFG, \"max_length\", 256))\n",
    "\n",
    "train_tok = train_hf.map(tok, batched=True)\n",
    "eval_tok  = eval_hf.map(tok, batched=True)\n",
    "\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
    "eval_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    return {\"precision\": float(p), \"recall\": float(r), \"f1\": float(f1)}\n",
    "\n",
    "# ---- TrainingArguments: compatible with older/newer transformers ----\n",
    "import inspect\n",
    "ta_params = set(inspect.signature(TrainingArguments).parameters.keys())\n",
    "\n",
    "ta_kwargs = dict(\n",
    "    output_dir=\"../models/finetuned_patentsberta\",\n",
    "    num_train_epochs=getattr(CFG, \"ft_epochs\", 1),\n",
    "    learning_rate=getattr(CFG, \"ft_lr\", 1e-5),\n",
    "    per_device_train_batch_size=getattr(CFG, \"ft_batch_size\", 8),\n",
    "    per_device_eval_batch_size=getattr(CFG, \"ft_eval_batch_size\", 16),\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# evaluation strategy name differs across versions\n",
    "if \"eval_strategy\" in ta_params:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "elif \"evaluation_strategy\" in ta_params:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "\n",
    "training_args = TrainingArguments(**ta_kwargs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_metrics = trainer.evaluate()\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "out_dir = \"../models/finetuned_patentsberta\"\n",
    "trainer.save_model(out_dir)\n",
    "tokenizer.save_pretrained(out_dir)\n",
    "print(f\"Saved model to {out_dir}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
